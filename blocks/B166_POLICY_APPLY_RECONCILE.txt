BLOCK: B166_POLICY_APPLY_RECONCILE
VERSION: v1.10
STATUS: ACTIVE
OWNER: Marco + ChatGPT
LAST-UPDATE: 2026-01-09

================================================================================
1) ZWECK
================================================================================
- Definiert die komplette Policy-Apply / Restricted-Sync-Kette.
- Ziel: Kein Drift zwischen SQL (Source of Truth) und Kernel-Enforcement (nftables/tc).
- Änderungen (Claim/Unclaim/Quota/Expiry/Manual/Speed) müssen sofort wirken.
- Hinweis: Email-Verify (Verify-Wall) ist App-Layer und kein Kernel-Policy-Trigger.
- Safety-Net: Reconcile repariert Drift spätestens innerhalb <= 5 Minuten.

================================================================================
2) GRUNDREGELN
================================================================================
- SQL ist Source of Truth (B050).
- Enforcement passiert im Kernel:
  - Restricted Mode über nftables Set (z.B. restricted_v4) (B150).
  - Speed/QoS über tc pro pppX.
- Kein SQL pro Paket: DB-Reads/Writes sind Control-Plane (Events/Timer), nicht Datenpfad.
- Fail-Closed für neue VPN-Logins bleibt unverändert (B050): DB down => deny/reject für ALLE.
- Die konkrete Restricted-Allowlist (Ports/Protokolle inkl. DNS TCP + ICMP) ist in B150 "Restricted Allowlist" kanonisch definiert.

================================================================================
3) DRY: ZENTRALES TOOL (EINZIGE IMPLEMENTIERUNG)
================================================================================
- Alle Trigger (ip-up, Panel Events, Reconcile Timer) rufen ausschließlich ein zentrales Tool auf:
  - /usr/local/bin/vpn-policy-apply
- Keine Logik-Duplikate in Hooks oder Panel-Code.
- Das Tool ist idempotent: wiederholtes Anwenden erzeugt stets den gleichen Zustand.

================================================================================
4) SESSION-MAPPING (VORAUSSETZUNG)
================================================================================
- Runtime-Apply ist nur für aktive Sessions möglich.
- Aktive Sessions werden über Mapping-Files aus B165 ermittelt:
  - /run/vpn-sessions/<ppp_if>.env (volatile)
- Enthält mindestens:
  - PPP_IF=pppX
  - CLIENT_IP=10.77.x.y
  - CONNECTION_ID=<int>
  - SESSION_ID=<string>   (lokaler Identifier; nicht führend für Runtime-Aktivität)
  - START_TS=<unix>
  - PPPD_PID=<int>        (MUST Kill-Handle; pppd Prozess-PID dieser Session)
- PPPD_PID Herkunft (MUST):
  - PPPD_PID MUSS aus dem von pppd/ip-up bereitgestellten Environment stammen.
  - FORBIDDEN: pgrep/ps zur PID-Ermittlung (Race-Condition / falscher Prozess möglich).
- PPPD_PID ist die kanonische Runtime-Referenz für den Fail-Safe "PPP Session Kill".
  - Safety-Check (MUST): Vor einem Kill MUSS zusätzlich PPP_IF + START_TS aus dem Mapping plausibilisiert werden (PID-Reuse-Schutz).
- SESSION_ID bleibt rein diagnostisch (Logs/UI) und ist KEIN Kill-Handle.
- Runtime-Aktivität (KANONISCH, Definition siehe B165/B167):
  - "connection_id aktiv?" => true genau dann, wenn irgendein /run/vpn-sessions/*.env diese CONNECTION_ID enthält.
  - Diese Runtime-Quelle ist führend für Apply (online/offline), Reconcile und Safety-Checks (Janitor-Integration).
- Offline Connections haben kein Mapping => es gibt nichts am Kernel zu ändern; Policy greift beim nächsten ip-up.
- Reconcile purgt stale /run/vpn-sessions Mappings deterministisch (PPP_IF muss im Kernel existieren), damit /run als Safety-Quelle zuverlässig bleibt.

================================================================================
5) MODI DES TOOLS
================================================================================
Modus A: Single Target (STRICT)
- Aufruf: vpn-policy-apply --connection-id=<id>
- Verwendet von: ip-up Hook + Panel Events (wenn einzelne Connection betroffen ist)

Modus B: Reconcile All (BEST EFFORT)
- Aufruf: vpn-policy-apply --reconcile-all
- Verwendet von: systemd timer (alle 5 Minuten)

Optional Modus C: Customer Scope (STRICT)
- Aufruf: vpn-policy-apply --customer-id=<id>
- Verwendet von: Bulk-Änderungen auf Customer-Ebene (z.B. Admin-Tool: Quota/Expiry für mehrere Connections eines Customers), um nicht viele Einzelaufrufe zu benötigen.

================================================================================
6) APPLY-LOGIK (SINGLE TARGET)
================================================================================
Ablauf: vpn-policy-apply --connection-id=<id>

1) SQL lesen (Control-Plane)
- Lade effective Policy für diese connection_id:
  - restricted_effective (bool)
- restricted_reason (string; z.B. UNCLAIMED_OVERDUE / QUOTA / EXPIRY / MANUAL)
  - Hinweis: Verify-Wall ist App-Layer und erscheint NICHT als restricted_reason.
  - speed_profile / rate-limit (falls aktiv)

2) Online/Offline feststellen (Mapping)
- Suche aktive Session in /run/vpn-sessions/ anhand CONNECTION_ID=<id>
- FALL ONLINE:
  - CLIENT_IP + PPP_IF verfügbar => Kernel-Enforcement wird gesetzt
- FALL OFFLINE:
  - keine Kernel-Änderung möglich/nötig -> "offline noop" (Exit 0)

3) Kernel-Enforcement setzen (ONLINE)
- nftables Set:
  - restricted_effective=true  => CLIENT_IP in restricted_v4 hinzufügen
  - restricted_effective=false => CLIENT_IP aus restricted_v4 entfernen
- tc:
  - speed_profile auf PPP_IF anwenden (tc qdisc/filters replace)
  - falls kein speed limit: definierte Default/cleanup anwenden

3.1) HARD CUT: STATE-FLUSH + FAIL-SAFE (IMMEDIATE ENFORCEMENT für ESTABLISHED Flows)
- Ziel: Wenn restricted_effective=true wird, müssen auch bereits ESTABLISHED Flows sofort enden (kein Soft Cut).
- Trigger: Hard Cut nur bei Transition UNRESTRICTED -> RESTRICTED (idempotent, nicht bei jedem Apply).
  - old_kernel_restricted = (CLIENT_IP ist vor dem Apply bereits Element von restricted_v4)  [Kernel-Pre-Check]
  - Pre-Check MUSS vor jeder Änderung am Set erfolgen (sonst ist die Transition-Erkennung nicht zuverlässig).
  - new_restricted = restricted_effective (aus SQL)
- Kritische Reihenfolge (Race-sicher, MUST):
  1) Policy Update: nftables/tc Enforcement setzen (Restricted-Set + Speed), sodass die Blockade im Kernel aktiv ist
  2) Hard Cut auslösen, aber nur wenn (old_kernel_restricted=false AND new_restricted=true)
  3) Audit/Log: reason + connection_id + client_ip + "hard_cut=1" + Methode/Outcome
- Primärmechanismus (conntrack-first, MUST):
  - Conntrack-States der CLIENT_IP löschen (bidirektional), damit "ct state established,related accept" nicht als Bypass wirken kann.
  - Flush Scope (verbindlich):
    - Es müssen ALLE Conntrack-Einträge gelöscht werden, die die CLIENT_IP enthalten (Source UND Destination / orig UND reply).
    - Implementation Note: z.B. conntrack delete für src + dst (oder äquivalente Netlink/API Calls).
- Preflight (MUST):
  - vpn-policy-apply MUSS deterministisch erkennen, ob Conntrack-Flush möglich ist (Tooling/Capabilities vorhanden).
  - Wenn Conntrack-Flush "unavailable" ist (Tool fehlt / keine Rechte / nicht ausführbar), gilt der Primärmechanismus als nicht verfügbar und der Fail-Safe ist sofort auszuführen.
- Fail-Safe (MUST): PPP Session Kill, falls Flush fehlschlägt oder unavailable ist
  - Wenn der Conntrack-Flush fehlschlägt ODER nicht verfügbar ist, MUSS die aktive PPP-Session sofort beendet werden (Fail-Safe "Notbremse").
  - Die Ziel-Session ist kanonisch über die Runtime-Mapping-Daten identifiziert:
    - PPPD_PID (MUST Kill-Handle) + PPP_IF + START_TS aus /run/vpn-sessions/<ppp_if>.env
    - SESSION_ID ist optional (nur Diagnose), NICHT Kill-Handle
  - Erwartung: "Wo kein PPP_IF ist, kann kein Traffic fließen" => Hard Cut ist deterministisch erfüllt.
- Fehlerbehandlung (STRICT, Single Target):
  - Wenn Hard Cut getriggert ist (Transition UNRESTRICTED->RESTRICTED):
    - Wenn Flush erfolgreich: OK.
    - Wenn Flush fehlschlägt oder unavailable: PPP Session Kill MUSS versucht werden.
      - Wenn PPP Kill erfolgreich: OK (Hard Cut erfüllt), aber Audit/Log MUSS "hard_cut_fallback=ppp_kill" setzen.
      - Wenn PPP Kill ebenfalls fehlschlägt: RUNTIME_APPLY_ERROR (Exit 4).
  - Begründung: Manual/Quota/Expiry/Unclaimed-Overdue müssen wirklich "hard" sofort wirken. Silent Failure ist inakzeptabel.

================================================================================
7) APPLY-LOGIK (CUSTOMER SCOPE, OPTIONAL)
================================================================================
Ablauf: vpn-policy-apply --customer-id=<id>
- Ziel: Bulk-Operationen kundenweit anwenden (z.B. Admin-Tool: Quota/Expiry/Speed/Manual für mehrere Connections), ohne viele Einzelaufrufe zu benötigen.
- SQL:
  - Ermittelt alle CLAIMED connection_ids des customers + deren effective policy
- Runtime:
  - Nur aktive Sessions (mit Mapping) werden im Kernel geändert
  - Offline Connections werden nicht im Kernel "vorgehalten" (wirkt beim nächsten ip-up)

================================================================================
8) RECONCILE (SAFETY-NET, OPTION B)
================================================================================
Ablauf: vpn-policy-apply --reconcile-all  (BEST EFFORT)

1) Ist-Liste (nur aktive Sessions)
- Enumeriere /run/vpn-sessions/*.env
- Erzeuge Liste: (connection_id, client_ip, ppp_if)

0.1) /run Mapping Hygiene (deterministisch)
- Problem: /run/vpn-sessions kann stale Mapping-Files enthalten (z.B. ip-down nicht gelaufen).
- Regel: Ein Mapping ist nur gültig, wenn das referenzierte PPP_IF tatsächlich existiert.

Ablauf:
- Für jedes /run/vpn-sessions/<ppp_if>.env:
  - Prüfe, ob /sys/class/net/<PPP_IF>/ existiert.
  - Wenn NICHT existent:
    - Mapping-File löschen (stale mapping purge)
    - optional loggen (INFO)
- Danach erst Ist-Liste aufbauen (nur noch valide Mappings).


2) Batch SQL Query (performant, kein N+1)
- Lade effective policy für alle aktiven connection_ids in einem Batch:
  - SELECT ... WHERE id IN (...)

3) Apply für jede aktive Session (BEST EFFORT)
- Setze nft/tc pro Session entsprechend der SQL policy
- Fehler einzelner Sessions werden geloggt, Reconcile läuft weiter

4) Restricted-Set Rebuild (deterministisch, EXAKT)
Ziel:
- restricted_v4 soll EXAKT den Sollzustand abbilden:
  desired_restricted_ips = { CLIENT_IP aller aktiven Sessions, bei denen restricted_effective=true }

Ablauf:
- Baue aus Schritt (1)+(2) die Sollmenge:
  - Für jede aktive Session:
    - wenn SQL restricted_effective=true -> CLIENT_IP in desired_restricted_ips aufnehmen
- Setze Kernel-Zustand deterministisch auf Soll (EXAKT, ohne Leak-Window):
  - Ermittle Kernel-Istzustand:
    - current_restricted_ips = Elemente aus restricted_v4 (Kernel)
  - Delta bestimmen:
    - to_add = desired_restricted_ips \ current_restricted_ips
    - to_del = current_restricted_ips \ desired_restricted_ips
  - Set-Update (deterministisch):
    - MUST: Update in EINER atomaren nftables Transaktion/Commit (ein einziger nft-Batch/Netlink-Commit).
    - to_del löschen (stale Elemente entfernen)
    - to_add hinzufügen (fehlende Elemente ergänzen)
    - Hinweis: "FLUSH + rebuild" ist nur erlaubt, wenn Flush+Add garantiert im selben atomaren Commit passiert (kein separater Flush-Call).
    - HARD CUT bei Drift-Fix (best effort):
      - Für jede IP in to_add (neu restricted durch Reconcile): nach erfolgreichem nft-Commit MUSS versucht werden,
        Conntrack-States der IP zu löschen (bidirektional), damit auch bestehende ESTABLISHED Flows sofort gekappt werden.
      - Wenn Conntrack-Flush fehlschlägt oder unavailable ist:
        - Fail-Safe SHOULD: PPP Session Kill für die betroffene aktive Session (über Mapping: connection_id/ppp_if/session_id aus Schritt 1),
          um Hard Cut deterministisch zu erzwingen.
      - Fehlerbehandlung im Reconcile:
        - Flush fail, aber PPP Kill erfolgreich => log WARN ("hard_cut_fallback=ppp_kill"), Reconcile läuft weiter.
        - Flush fail und PPP Kill fail => log ERROR, Reconcile läuft weiter; Ergebnis "partial" (Exit 1) wenn solche Fehler auftraten.
Ergebnis:
- Keine Drift möglich: stale IPs verschwinden garantiert
- Unlock/Verify/Quota wirkt spätestens <=5 Minuten, auch wenn Event verpasst wurde
Hinweis:
- Offline Connections werden NICHT im Set vorgehalten (kein Mapping => keine aktive IP). Wirkung erfolgt beim nächsten ip-up (Single Target).

5) Timing
- Reconcile läuft alle 5 Minuten => Drift wird spätestens innerhalb <= 5 Minuten korrigiert

================================================================================
9) TRIGGER-KETTE (WER RUFT WAS AUF?)
================================================================================
Trigger 1: ip-up Hook (pppd)
- MUSS: vpn-policy-apply --connection-id=<id>
- Zweck: sofortige Wirkung beim Connect (restricted/tc ohne Zeitfenster)

Trigger 2: ip-down Hook (pppd)
- SOLL: final accounting flush (B165/B050)
- SOLL: cleanup enforcement (stale vermeiden), aber Reconcile kann es notfalls reparieren

Trigger 3: Panel Events
- MUSS apply triggern bei:
  - Claim done/revoked -> --connection-id
  - Quota reset/refill -> --connection-id
  - Expiry extend -> --connection-id
  - Manual Restrict/Unrestrict -> --connection-id
  - Speed change -> --connection-id
- Email-Verify (PENDING->ACTIVE) ist App-Layer (Verify-Wall) und kein Kernel-Policy-Trigger. Kein nft/tc Apply erforderlich.

Trigger 4: Reconcile Timer (systemd, 5 Minuten)
- MUSS: vpn-policy-apply --reconcile-all
- Zweck: Drift-Reparatur + stale cleanup + self-healing
- Wiring (PPP Hooks + systemd Timer/Services) ist in B167 verbindlich definiert.

================================================================================
10) STRICT vs BEST EFFORT (ENTSCHEIDUNG)
================================================================================
- Single Target (ip-up, Panel Event, optional customer scope) = STRICT:
  - nft/tc Fehler => harter Fehler
  - conntrack (Hard Cut Flush) Fehler ist ALLEIN kein harter Fehler, sofern der Fail-Safe PPP Session Kill erfolgreich war (Hard Cut erfüllt).
  - Harte Fehlerbedingung (Exit 4) nur wenn Hard Cut getriggert ist UND (Flush failed/unavailable) UND (PPP Kill failed).
- Reconcile All = BEST EFFORT:
  - korrigiert so viel wie möglich; einzelne Fehler verhindern nicht die Korrektur anderer Sessions
  - conntrack flush Fehler für einzelne IPs: log + continue; Ergebnis "partial" (Exit 1) wenn Fehler auftraten
  - kann "partial" melden (Exit 1), aber beendet erfolgreich, nachdem es gearbeitet hat

================================================================================
10.5) CONCURRENCY / SINGLE-WRITER (MUST)
================================================================================
- Ziel: Apply/Reconcile darf niemals parallel laufen (Race auf nft/tc + inkonsistenter Zustand möglich).
- Mindestanforderungen:
  - Es existiert ein Single-Writer Lock vor jeder Apply/Reconcile-Ausführung.
  - Wenn Lock belegt: sauber abbrechen über EXIT 5 = TEMPFAIL_LOCKED (keine Partial Applies).
  - Stale-Lock Handling: definierte TTL/Break-Glass, damit ein Crash nicht dauerhaft blockiert.
  - Idempotenz: Wiederholung nach TEMPFAIL/Crash stellt deterministischen Endzustand wieder her.
- Implementationshinweis:
  - Die konkrete Mechanik (z.B. flock Lockfile unter /run) wird im Wiring-Block B167 verbindlich verdrahtet.

================================================================================
11) EXIT-CODES (STANDARD)
================================================================================
- 0 = OK (Applied / Noop offline / Reconcile OK)
- 1 = PARTIAL_OK (nur --reconcile-all: einige Sessions nicht applied; Reconcile hat trotzdem gearbeitet)
- 2 = TEMPFAIL_SQL (SQL/DB nicht erreichbar)
- 3 = INVALID_ARGS / INPUT_ERROR
- 4 = RUNTIME_APPLY_ERROR (nft/tc/tool/permission/syntax)
- 5 = TEMPFAIL_LOCKED (optional: lock aktiv, reconcile läuft schon)
- 6 = STATE_MAPPING_ERROR (Mapping-Datei beschädigt/unvollständig)
- 7 = INTERNAL_ERROR (unerwarteter Fehler)

Offline ist KEIN Fehler:
- --connection-id=<id> ohne aktives Mapping => Exit 0 + INFO "offline noop"

================================================================================
12) DB-DOWN KONSISTENZ (ZU FAIL-CLOSED)
================================================================================
- DB down:
  - AAA (neue VPN-Logins): Fail-Closed (deny/reject für ALLE)
  - vpn-policy-apply: TEMPFAIL_SQL (Exit 2), keine Änderung möglich
  - Bestehende Sessions bleiben enforced, wie Kernel gerade steht
- DB recovery:
  - Panel Events können wieder apply auslösen
  - Reconcile korrigiert Zustand spätestens innerhalb <=5 Minuten
- D1a Connect-Gate (No-Unpoliced-Window ohne Default-Restricted):
  - ip-up setzt CLIENT_IP in connect_pending_v4 (deny-all forward) bevor vpn-policy-apply startet.
  - Bei TEMPFAIL_SQL/ERROR/TIMEOUT bleibt das Gate aktiv und ip-up terminiert die PPP-Session (FAIL-CLOSED, siehe B167/D009).
  - Kein Fallback auf Portal/Restricted bei SQL-Ausfall.

================================================================================
13) TESTS (MINIMUM)
================================================================================
- Connect Apply Test: PPP connect -> ip-up ruft single apply -> restricted/tc sofort gesetzt.
- Panel Event Test: Quota reset/refill oder Expiry extend oder Manual Restrict/Unrestrict -> apply -> restricted_v4 sofort angepasst.
- Hard Cut (ESTABLISHED) Test: Starte einen großen Download/Stream über VPN (Flow ESTABLISHED). Setze restricted_effective=true (Quota/Manual/Expiry) und triggere apply.
  Erwartung: Datenfluss wird sofort unterbrochen (Conntrack-Flush), danach nur allowlist zu 10.77.0.1 möglich.
- Hard Cut Fallback Test (Flush unavailable/fail):
  - Simuliere Conntrack-Flush nicht verfügbar oder fehlschlagend (Tool/Cap/Permission).
  - Setze restricted_effective=true und triggere single apply.
  - Erwartung: PPP Session Kill greift deterministisch; Traffic stoppt sofort; Audit/Log zeigt "hard_cut_fallback=ppp_kill".
- Reconcile Delta Hard Cut Test: Simuliere missed event:
  - Client ist restricted_effective=true in SQL, aber CLIENT_IP ist manuell aus restricted_v4 entfernt.
  - Starte Datenfluss (ESTABLISHED) ins WAN.
  - Reconcile läuft: IP kommt zurück ins Set (to_add) UND Flow wird sofort gekappt (Conntrack-Flush im Reconcile).
- Atomic Update Safety Test: Während Reconcile läuft darf kein Leak-Window entstehen (kein Zeitraum, in dem restricted_v4 "leer" ist, obwohl desired non-empty).
  Validierung pragmatisch: Dauertraffic + paralleles Reconcile; es darf niemals WAN-Traffic für restricted Clients durchkommen.
- Missed Event Drift Test: Panel Änderung ohne apply -> Reconcile korrigiert <=5 Minuten.
- Stale Cleanup Test: Disconnect ohne cleanup -> Reconcile entfernt stale IP aus restricted_v4.
- SQL Down Test: apply/reconcile -> Exit 2; keine neuen VPN-Logins (Fail-Closed). Nach DB up -> Reconcile korrigiert.
- Strict vs Best Effort Test:
  - Single apply: nft Fehler -> Exit 4
  - Reconcile: ein Session-Fehler -> Exit 1, andere Sessions werden korrigiert
- Stale /run Mapping Purge Test: /run enthält pppX.env aber /sys/class/net/pppX fehlt -> Reconcile löscht Mapping -> verhindert false "live" Safety-Blockade.
- Restricted Set Rebuild Test: restricted_v4 enthält manuell/stale IPs -> Reconcile delta-update (to_del/to_add, atomarer Commit) -> Set enthält exakt desired_restricted_ips (aktive+restricted=true), sonst nichts.
- Connect No-Leak Gate Test (D1a):
  - Simuliere Delay im Connect-Pfad (z.B. vpn-policy-apply sleep 10).
  - Erwartung: Während connect_pending_v4 aktiv ist, fließt kein Forward-Traffic (WAN=0), auch wenn PPP bereits „up“ ist.
  - Nach SUCCESS: Gate entfernt, dann gilt restricted/full gemäß SQL.
  - Bei TEMPFAIL_SQL oder Timeout: PPP Kill, Gate bleibt bis Cleanup; kein Traffic-Leak.

================================================================================
14) CHANGELOG
================================================================================
- v1.10 (2026-01-10): D1a Connect-Gate integriert: connect_pending_v4 Semantik bei DB-down/Apply-Fail dokumentiert + Acceptance-Test „No-Leak Gate“ ergänzt (Verweis B167/D009).
- v1.9 (2026-01-09): Kill-Handle kanonisiert: PPPD_PID als MUST, mit Plausibilitätscheck über PPP_IF + START_TS; SESSION_ID ausdrücklich nur Diagnose.
  STRICT-Semantik präzisiert: Conntrack-Flush-Fail ist nicht fatal, wenn PPP-Kill erfolgreich; Exit 4 nur bei Double-Fail.
- v1.8 (2026-01-09): Hard Cut erweitert um Fail-Safe: conntrack-first + PPP Session Kill bei Flush failure/unavailable (deterministisch).
  Preflight-Regel ergänzt (Flush availability), Failure-Semantik präzisiert (Single Target: Kill-success = OK mit Audit-Flag; double-fail = Exit 4).
  Reconcile Hard-Cut erweitert um optionalen PPP-Kill-Fallback; Tests um Fallback-Fall ergänzt.
- v1.7 (2026-01-09): HARD CUT spezifiziert: Conntrack-Flush bei Transition UNRESTRICTED->RESTRICTED (enforce->flush, bidirektionaler Scope, STRICT in Single Apply).
  Reconcile erweitert um Delta-Erkennung (to_add/to_del) + best-effort Hard Cut für newly restricted IPs.
  Restricted-Set Update als atomare nft-Transaktion/Commit festgenagelt (kein Leak-Window). Tests entsprechend erweitert.
- v1.6 (2026-01-07): Concurrency/Singe-Writer Regeln ergänzt (TEMPFAIL_LOCKED Semantik + Stale-Lock Handling), ohne Apply/Reconcile-Logik zu ändern.
- v1.5: Kernel-Triggerliste bereinigt (Verify entfernt, Unclaim+Manual ergänzt); Trigger 3 Panel Events strukturell korrigiert + Manual Restrict/Unrestrict als Apply-Event ergänzt; Runtime-Aktivitätsdefinition pro connection_id (scan /run/vpn-sessions/*.env) als kanonisch dokumentiert (B165/B167).
- v1.4: Gate#1/Gate#2-Reste entfernt; restricted_reason Beispiele auf QUOTA/EXPIRY/MANUAL/UNCLAIMED_OVERDUE aktualisiert; Customer-Scope Zweck auf Bulk-Apply (ohne Gate#2) korrigiert; Tests bereinigt (Verify done ist App-Layer, kein Apply).
- v1.3: Email-Verify aus Kernel-Triggern entfernt (Verify-Wall App-Layer). Customer-Scope Apply bleibt für Bulk-Operationen (Quota/Expiry/Admin) statt Gate#2.
- v1.2: Reconcile Step 4 auf deterministischen restricted_v4 Rebuild umgestellt (flush+rebuild nach desired_restricted_ips), inkl. Test.
- v1.1: Reconcile ergänzt um deterministischen Purge stale /run/vpn-sessions Mappings (PPP_IF Existenzcheck), inkl. Test.
- v1.0: initial (event-driven apply + 5min reconcile; DRY tool; strict vs best effort; exit-codes)
================================================================================